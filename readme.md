# GradMDM

This repository contains the result and the sample code for the work:
[GradMDM: Adversarial Attack on Dynamic Networks](https://arxiv.org/pdf/2304.06724.pdf)
by
[Jianhong Pan](scholar.google.com/citations?user=J_IepqIAAAAJ), 
[Lin Geng Foo](scholar.google.com/citations?user=BDEOhasAAAAJ),
[Qichen Zheng](scholar.google.com/citations?user=d6AbpzgAAAAJ), 
[Zhipeng Fan](scholar.google.com/citations?user=Nb6ggPwAAAAJ), 
[Hossein Rahmani](scholar.google.com/citations?user=zFyT_gwAAAAJ),
[Qiuhong Ke](scholar.google.com/citations?user=84qxdhsAAAAJ), and 
[Jun Liu](scholar.google.com/citations?user=Q5Ild8UAAAAJ&hl)

### Citation

If you find our project useful in your research, please consider citing:

```
@article{pan2023gradmdm,
  title={GradMDM: Adversarial Attack on Dynamic Networks},
  author={Pan, Jianhong and Foo, Lin Geng and Zheng, Qichen and Fan, Zhipeng and Rahmani, Hossein and Ke, Qiuhong and Liu, Jun},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2023},
  publisher={IEEE}
}
```

## Abstract
Dynamic neural networks can greatly reduce computation redundancy without compromising accuracy by adapting their structures based on the input. In this paper, we explore the robustness of dynamic neural networks against energy-oriented attacks targeted at reducing their efficiency. Specifically, we attack dynamic models with our novel algorithm GradMDM. GradMDM is a technique that adjusts the direction and the magnitude of the gradients to effectively find a small perturbation for each input, that will activate more computational units of dynamic models during inference. We evaluate GradMDM on multiple datasets and dynamic models, where it outperforms previous energy-oriented attack techniques, significantly increasing computation complexity while reducing the perceptibility of the perturbations. 

<div align=center>
<img src=".img/Sample.png"><br>
Figure 1: Visualizations of perturbed images generated by GradMDM and ILFO (Baseline).
</div>


# To perturb adversarial samples to SkipNet on the ImageNet validation dataset
## Prerequisite 
1. We support training with Pytorch 1.10.0. To install required packages
```
conda install pytorch=1.10 torchvision cudatoolkit=<the CUDA version you want> numpy
```

2. To prepare ImageNet dataset, please follow this [link](https://github.com/facebook/fb.resnet.torch/blob/master/INSTALL.md#download-the-imagenet-dataset).

3. To prepare SkipNet pretrained model, please follow this [link](https://github.com/ucbdrive/skipnet/tree/master/imagenet).


## Training 
1. To train the adversarial samples with $gamma=100$, run
```
python -u train_gradmdm.py --model-type rl --gamma 100
```
2. To train the adversarial samples without accuracy drop, run
```
python -u train_gradmdm.py --model-type rl --gamma 100 --acc-maintain
```